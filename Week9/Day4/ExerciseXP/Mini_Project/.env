LLM_BACKEND=groq
GROQ_API_KEY=xxx
GROQ_BASE_URL=https://api.groq.com/openai/v1
LLM_MODEL=llama-3.3-70b-versatile

# External server 1 : filesystem
MCP_FILES_CMD=npx
MCP_FILES_ARGS=@modelcontextprotocol/server-filesystem /home/yacine/mcp_root

# External server 2 : web
MCP_WEB_CMD=npx
MCP_WEB_ARGS=@modelcontextprotocol/server-web

# YOUR SERVER : mandatory for PART 2
MCP_LOCAL_CMD=python
MCP_LOCAL_ARGS=my_mcp_server.py
