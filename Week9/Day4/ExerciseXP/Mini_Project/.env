# Mini Project – MCP Agentic Application (Part 1 + Part 2)
# This file implements ONLY the Streamlit UI.
# The core logic (MCP servers, custom tools, LLM planning, orchestration) is
# implemented in:
# - my_mcp_server.py        → custom MCP server and tools (Part 2)
# - mcp_multi_client.py     → multi-server MCP client (external + custom)
# - llm_client.py           → LLM planning (Groq/Ollama)
# - orchestrator.py         → agentic orchestration using all tools.
# This UI calls run_agent_sync(...) from orchestrator.py.



# LLM configuration
LLM_BACKEND=groq
GROQ_API_KEY=YOUR_GROQ_KEY_HERE
GROQ_BASE_URL=https://api.groq.com/openai/v1
LLM_MODEL=llama-3.3-70b-versatile

# External MCP server 1: filesystem
MCP_FILES_CMD=npx
MCP_FILES_ARGS=@modelcontextprotocol/server-filesystem /home/yacine/mcp_root

# External MCP server 2: web/search
MCP_WEB_CMD=npx
MCP_WEB_ARGS=@modelcontextprotocol/server-web

# Your custom MCP server: local_insights (Part 2 requirement)
MCP_LOCAL_CMD=python
MCP_LOCAL_ARGS=my_mcp_server.py
